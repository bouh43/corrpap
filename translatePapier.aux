\relax 
\providecommand\hyper@newdestlabel[2]{}
\catcode `:\active 
\catcode `;\active 
\catcode `!\active 
\catcode `?\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{caron2016humanoids}
\select@language{french}
\@writefile{toc}{\select@language{french}}
\@writefile{lof}{\select@language{french}}
\@writefile{lot}{\select@language{french}}
\newcplabel{^_1}{1}
\citation{Dumora2013}
\citation{Sato94}
\citation{Hoffman2010}
\citation{Ivaldi2014activeExplo,csahin2007afford,Jamone2017affordance}
\citation{Wang2013ijrr,Thill2017hri}
\citation{Zube2016,Ivaldi2010}
\citation{alami2006toward,shah2011improved}
\citation{Busch2017,Dragan2013rss}
\citation{Calinon2014,khansari2011learning}
\citation{ijspeert2013dynamical}
\citation{meier2016probabilistic}
\citation{paraschos2013probabilistic}
\@writefile{toc}{\contentsline {section}{\numberline {1}INTRODUCTION}{2}{section.1}}
\citation{HandbookRobotLearning}
\citation{2013ACTI2891}
\citation{paraschos2015model}
\citation{paraschos2013probabilistic}
\citation{maeda2016probabilistic}
\citation{maeda2014learning}
\citation{maeda2014learning}
\citation{meier2016probabilistic}
\citation{paraschos2013probabilistic}
\citation{paraschos2015model}
\citation{pattacini2010experimental}
\citation{ivaldi2011computing,fumagalli2012force}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Concepte d'utilisation des ProMPs dans lequel le robot pr\IeC {\'e}dit la trajectoire a effectuer dans le cadre de t\IeC {\^a}che collaborative. En haut : phase d'apprentissage, o\IeC {\`u} les ProMPs sont apprises \IeC {\`a} partir de plusieurs d\IeC {\'e}monstrations guid\IeC {\'e}s par un humain. Bas : phase d'inf\IeC {\'e}rence phase (en line), o\IeC {\`u} le robot reconna\IeC {\^\i }t, \IeC {\`a} partir d'un mouvement initi\IeC {\'e} par son partenaire, la ProMP courante et o\IeC {\`u} il pr\IeC {\'e}dit l'intention de son partenaire, \textit  {i.e.}, l'\IeC {\'e}volution future de la trajectoire initi\IeC {\'e}e.\relax }}{5}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:conceptProMP}{{1}{5}{Concepte d'utilisation des ProMPs dans lequel le robot prédit la trajectoire a effectuer dans le cadre de tâche collaborative. En haut : phase d'apprentissage, où les ProMPs sont apprises à partir de plusieurs démonstrations guidés par un humain. Bas : phase d'inférence phase (en line), où le robot reconnaît, à partir d'un mouvement initié par son partenaire, la ProMP courante et où il prédit l'intention de son partenaire, \textit {i.e.}, l'évolution future de la trajectoire initiée.\relax }{figure.caption.1}{}}
\citation{demiris2007prediction}
\citation{kim2017collaborative}
\citation{dragan2014integrating}
\citation{dragan2014integrating}
\citation{HuangHAD17}
\citation{sciutti2013robots}
\citation{Ivaldi2014}
\citation{ferrer2014bayesian}
\citation{wang2012probabilistic}
\citation{wang2005gaussian}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{6}{section.2}}
\newlabel{sec:SOA}{{2}{6}{Related Work}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.1}}Intention during human-robot interaction}{6}{subsection.2.1}}
\citation{csibra2007obsessed}
\citation{palinko2014communicative}
\citation{buxton2003learning}
\citation{amor2014interaction}
\citation{ijspeert2013dynamical}
\citation{gribovskaya2011motion}
\citation{rozo2013learning}
\citation{carlson2008human}
\citation{soh2015learning}
\citation{jarrasse2008can}
\citation{baraglia2016initiative}
\citation{ferrer2014bayesian}
\citation{gribovskaya2011motion}
\citation{wang2009hmm}
\citation{rozo2013learning}
\@writefile{toc}{\contentsline {section}{\numberline {3}MA VIEILLE PARTIE}{8}{section.3}}
\citation{carlson2008human}
\citation{soh2015learning}
\citation{jarrasse2008can}
\citation{baraglia2016initiative}
\citation{wang2012probabilistic}
\citation{wang2005gaussian}
\citation{demiris2007prediction}
\citation{csibra2007obsessed}
\citation{buxton2003learning}
\citation{fitts1992information}
\citation{langolf1976investigation}
\citation{langolf1976investigation}
\citation{soechting1984effect}
\citation{amor2014interaction}
\citation{keogh2002exact}
\citation{silva2016speeding}
\citation{maeda2014learning}
\citation{ijspeert2013dynamical,schaal2006dynamic,meier2016probabilistic}
\citation{meier2016probabilistic}
\citation{ewerton2015learning}
\citation{paraschos2013probabilisticTrajectory}
\citation{maeda2014learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {{3.1}}\leavevmode {\color  {green}\textit  {Movement primitives /}} Primitives de mouvement}{10}{subsection.3.1}}
\citation{billard2001learning}
\citation{fine1998hierarchical}
\citation{nguyen2005learning}
\citation{ren2002human}
\citation{evrard2009teaching}
\citation{fitts1992information}
\citation{langolf1976investigation}
\citation{langolf1976investigation}
\citation{soechting1984effect}
\citation{amor2014interaction}
\citation{keogh2002exact}
\citation{silva2016speeding}
\citation{maeda2014learning}
\citation{paraschos2013probabilistic}
\citation{maeda2014learning}
\citation{lober2014multiple,2013ACTI2891}
\citation{gmr}
\citation{hersch2008dynamical}
\citation{pbdlib}
\citation{Calinon16JIST}
\citation{StatisticalDynamical}
\citation{Calinon12Hum}
\citation{smlt}
\citation{pydmps}
\citation{ijspeert2013dynamical}
\citation{seds}
\citation{khansari2011learning}
\citation{khansari2012dynamical}
\citation{dmpbbo}
\citation{lober2014multiple,2013ACTI2891}
\citation{marcoProg}
\citation{ewerton2015learning}
\citation{icubLearningTrajectories}
\newlabel{table:software}{{\caption@xref {table:software}{ on input line 523}}{12}{Related open-source software}{table.caption.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Open-source software libraries implementing Movement Primitives and their application to different known robots.\relax }}{12}{table.caption.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{3.2}}Related open-source software}{12}{subsection.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Theoretical framework}{12}{section.4}}
\newlabel{sec:theory}{{4}{12}{Theoretical framework}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{4.1}}Notation}{13}{subsection.4.1}}
\newlabel{sec:notation}{{{4.1}}{13}{Notation}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{4.2}}Learning a Probabilistic Movement Primitive (ProMP) from demonstrations}{16}{subsection.4.2}}
\newlabel{LearningSimpleProMP}{{{4.2}}{16}{Learning a Probabilistic Movement Primitive (ProMP) from demonstrations}{subsection.4.2}{}}
\newlabel{eq:RBF}{{2}{16}{Learning a Probabilistic Movement Primitive (ProMP) from demonstrations}{equation.4.2}{}}
\newlabel{eq:w}{{3}{16}{Learning a Probabilistic Movement Primitive (ProMP) from demonstrations}{equation.4.3}{}}
\newlabel{eq:wInvertible}{{4}{17}{Learning a Probabilistic Movement Primitive (ProMP) from demonstrations}{equation.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{4.3}}Predicting the future movement from initial observations}{17}{subsection.4.3}}
\newlabel{sec:predict}{{{4.3}}{17}{Predicting the future movement from initial observations}{subsection.4.3}{}}
\newlabel{eq:inf}{{8}{17}{Predicting the future movement from initial observations}{equation.4.8}{}}
\citation{paraschos2013probabilistic,Bishop:2006}
\citation{paraschos2013probabilistic,paraschos2013probabilisticTrajectory}
\newlabel{eq:K}{{9}{18}{Predicting the future movement from initial observations}{equation.4.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{4.4}}Predicting the trajectory time modulation}{18}{subsection.4.4}}
\newlabel{sec:predictDuration}{{{4.4}}{18}{Predicting the trajectory time modulation}{subsection.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces This plot shows the predicted trajectory given early observations (data points, in black), compared to the ground truth (\textit  {e.g.}, the trajectory that the human intends to execute with the robot). We show the prior distribution (in light blue) and the posterior distribution (in red), which is computed by conditioning the distribution to match the observations. Here, the posterior simply uses the average $\alpha $ computed over the $\alpha _1, \ldots  , \alpha _K$ of the $K$ demonstrations. Without predicting the time modulation from the observations and using the average $\alpha $, the predicted trajectory has a duration that is visibly different from the ground truth.\relax }}{19}{figure.caption.3}}
\newlabel{fig:meanAlpha}{{2}{19}{This plot shows the predicted trajectory given early observations (data points, in black), compared to the ground truth (\textit {e.g.}, the trajectory that the human intends to execute with the robot). We show the prior distribution (in light blue) and the posterior distribution (in red), which is computed by conditioning the distribution to match the observations. Here, the posterior simply uses the average $\alpha $ computed over the $\alpha _1, \ldots , \alpha _K$ of the $K$ demonstrations. Without predicting the time modulation from the observations and using the average $\alpha $, the predicted trajectory has a duration that is visibly different from the ground truth.\relax }{figure.caption.3}{}}
\newlabel{eq:avg}{{11}{19}{Predicting the trajectory time modulation}{equation.4.11}{}}
\newlabel{eq:ml}{{12}{19}{Predicting the trajectory time modulation}{equation.4.12}{}}
\newlabel{eq:minDist}{{13}{19}{Predicting the trajectory time modulation}{equation.4.13}{}}
\citation{ewerton2015learning}
\citation{maeda2016probabilistic}
\newlabel{eq:model}{{14}{20}{Predicting the trajectory time modulation}{equation.4.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{4.5}}Recognizing one among many movement primitives}{20}{subsection.4.5}}
\newlabel{sec:ManyProMP}{{{4.5}}{20}{Recognizing one among many movement primitives}{subsection.4.5}{}}
\newlabel{eq:mostlikelypromp}{{15}{21}{Recognizing one among many movement primitives}{equation.4.15}{}}
\newlabel{eq:udateWithAlpha}{{16}{21}{Recognizing one among many movement primitives}{equation.4.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Software overview}{21}{section.5}}
\newlabel{sec:softwareOverview}{{5}{21}{Software overview}{section.5}{}}
\newlabel{sec:software}{{5}{21}{Software overview}{section.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Software architecture and data-flows.  The robot's control is done either by the user's guidance (manually or through a haptic device) represented in blue, or by the Matlab module, in purple. The C++ module handles the control source to command the robot, as represented in black. Moreover, this module forwards information that comes from the iCub.\relax }}{22}{figure.caption.4}}
\newlabel{fig:orgaSoftware}{{3}{22}{Software architecture and data-flows.\\ The robot's control is done either by the user's guidance (manually or through a haptic device) represented in blue, or by the Matlab module, in purple. The C++ module handles the control source to command the robot, as represented in black. Moreover, this module forwards information that comes from the iCub.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Software example: learning a 1-DOF primitive}{22}{section.6}}
\newlabel{sec:example1DOF}{{6}{22}{Software example: learning a 1-DOF primitive}{section.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The observed trajectories are represented in magenta. The corresponding ProMP is represented in blue. The following parameters are used: $\mathaccentV {bar}016{s}=100$ for the reference number of samples, $M=5$ for the number of RBFs spread over time, and $h=0.04$ (=$ 1 \over M^2$) the variance of the RBFs.\relax }}{24}{figure.caption.5}}
\newlabel{fig:1DOFtrajectoriesProMP}{{4}{24}{The observed trajectories are represented in magenta. The corresponding ProMP is represented in blue. The following parameters are used: $\bar {s}=100$ for the reference number of samples, $M=5$ for the number of RBFs spread over time, and $h=0.04$ (=$ 1 \over M^2$) the variance of the RBFs.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The ProMP computed for the test dataset (Figure \ref  {fig:1DOFtrajectoriesProMP}) using different numbers of basis functions: from left to right: $M=\{2,5,50\}$ basis functions before normalization, with a variance $h={1 \over M^2}$. \relax }}{25}{figure.caption.6}}
\newlabel{fig:1DOFtrajectoriesProMPbasis}{{5}{25}{The ProMP computed for the test dataset (Figure \ref {fig:1DOFtrajectoriesProMP}) using different numbers of basis functions: from left to right: $M=\{2,5,50\}$ basis functions before normalization, with a variance $h={1 \over M^2}$. \relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The prediction of the future trajectory given early observations, exploiting the information of the learned ProMP (Figure \ref  {fig:1DOFtrajectoriesProMP}). The plots show the predicted trajectories after 10\%, 30\%, 50\% and 80\% of observed data points.\relax }}{26}{figure.caption.7}}
\newlabel{fig:1DOFtrajectoriesPredictions}{{6}{26}{The prediction of the future trajectory given early observations, exploiting the information of the learned ProMP (Figure \ref {fig:1DOFtrajectoriesProMP}). The plots show the predicted trajectories after 10\%, 30\%, 50\% and 80\% of observed data points.\relax }{figure.caption.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces information about trajectories' duration\relax }}{27}{table.caption.8}}
\newlabel{tab:alphaProMP}{{2}{27}{information about trajectories' duration\relax }{table.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The prediction of the future trajectory given $n_{o}=40\%$ of early observations from the learned ProMP computed for the test dataset (Figure \ref  {fig:1DOFtrajectoriesProMP}). The plots show the predicted trajectory, using different criteria to estimate the best phases of the trajectory: using the average time modulation (Equation~\ref  {eq:avg}); using the distance criteria (Equation~\ref  {eq:minDist}); using the maximum log-likelihood (Equation~\ref  {eq:ml}); or using a model of time modulation according to the time variation (Equation~\ref  {eq:model}).\relax }}{27}{figure.caption.9}}
\newlabel{fig:1DOFtrajectoriesPredictionsDuration}{{7}{27}{The prediction of the future trajectory given $n_{o}=40\%$ of early observations from the learned ProMP computed for the test dataset (Figure \ref {fig:1DOFtrajectoriesProMP}). The plots show the predicted trajectory, using different criteria to estimate the best phases of the trajectory: using the average time modulation (Equation~\ref {eq:avg}); using the distance criteria (Equation~\ref {eq:minDist}); using the maximum log-likelihood (Equation~\ref {eq:ml}); or using a model of time modulation according to the time variation (Equation~\ref {eq:model}).\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Application on the simulated iCub: learning three primitives}{27}{section.7}}
\newlabel{sec:3ProMPsAppli}{{7}{27}{Application on the simulated iCub: learning three primitives}{section.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Left: the three colored targets that the robot must reach from the starting point; the corresponding trajectories are used to learn three primitives representing three skills. Right: the Cartesian position information of the demonstrated trajectories for the three reaching tasks.\relax }}{28}{figure.caption.10}}
\newlabel{fig:3TargetsTrajectories}{{8}{28}{Left: the three colored targets that the robot must reach from the starting point; the corresponding trajectories are used to learn three primitives representing three skills. Right: the Cartesian position information of the demonstrated trajectories for the three reaching tasks.\relax }{figure.caption.10}{}}
\newlabel{fig:GazeboGoal}{{8}{28}{Left: the three colored targets that the robot must reach from the starting point; the corresponding trajectories are used to learn three primitives representing three skills. Right: the Cartesian position information of the demonstrated trajectories for the three reaching tasks.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{7.1}}Predicting intended trajectories by using ProMPs}{28}{subsection.7.1}}
\newlabel{sec:formulateModelInt}{{{7.1}}{28}{Predicting intended trajectories by using ProMPs}{subsection.7.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {{{7.1}.1}}Learning motion primitives}{29}{subsubsection.7.1.1}}
\newlabel{learning}{{{{7.1}.1}}{29}{Learning motion primitives}{subsubsection.7.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {{{7.1}.2}}Prediction of the trajectory evolution from initial observations}{29}{subsubsection.7.1.2}}
\newlabel{prediction}{{{{7.1}.2}}{29}{Prediction of the trajectory evolution from initial observations}{subsubsection.7.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{7.2}}Setup for simulated iCub}{30}{subsection.7.2}}
\newlabel{subec:Setup}{{{7.2}}{30}{Setup for simulated iCub}{subsection.7.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{7.3}}Data acquisition}{31}{subsection.7.3}}
\newlabel{sec:dataAquisition}{{{7.3}}{31}{Data acquisition}{subsection.7.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{7.4}}Learning the ProMPs}{31}{subsection.7.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{7.5}}Predicting the desired movement}{32}{subsection.7.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The Cartesian position in the $z$-axis of the three ProMPs corresponding to reaching three targets. There are $39$ trajectory demonstrations per each ProMPm with M=5 basis functions, $c={1 \over M}, h={1 \over M^2}$ and $\mathaccentV {bar}016{s} = 100$.\relax }}{33}{figure.caption.11}}
\newlabel{fig:3TargetsZTrajectoriesProMP}{{9}{33}{The Cartesian position in the $z$-axis of the three ProMPs corresponding to reaching three targets. There are $39$ trajectory demonstrations per each ProMPm with M=5 basis functions, $c={1 \over M}, h={1 \over M^2}$ and $\bar {s} = 100$.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{7.6}}Predicting the time modulation}{34}{subsection.7.6}}
\newlabel{sec:simulatedTimeModulationModels}{{{7.6}}{34}{Predicting the time modulation}{subsection.7.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces (top left) Error of $\alpha $ estimation; (top right and bottom) error of trajectory prediction according to the number of known data and the method used. We executed 10 different trials for each case.\relax }}{34}{figure.caption.12}}
\newlabel{fig:analyseAlpha}{{10}{34}{(top left) Error of $\alpha $ estimation; (top right and bottom) error of trajectory prediction according to the number of known data and the method used. We executed 10 different trials for each case.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Application on the real iCub}{35}{section.8}}
\newlabel{sec:appliRealIcub}{{8}{35}{Application on the real iCub}{section.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{8.1}}Three simple actions with wrench information}{35}{subsection.8.1}}
\citation{ivaldi2017towards}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Top left: the iCub and the visualization of the three targets in its workspace, defining the three tasks A-B-C. Top right: Cartesian position information of the demonstrated trajectories for the three tasks. Bottom left and right: wrench (force and moment) information of the demonstrated trajectories. \relax }}{37}{figure.caption.13}}
\newlabel{fig:realAppli}{{11}{37}{Top left: the iCub and the visualization of the three targets in its workspace, defining the three tasks A-B-C. Top right: Cartesian position information of the demonstrated trajectories for the three tasks. Bottom left and right: wrench (force and moment) information of the demonstrated trajectories. \relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The ProMPs learned by the robot from the demonstrations of Figure \ref  {fig:realAppli}.\relax }}{38}{figure.caption.14}}
\newlabel{fig:realDistribution}{{12}{38}{The ProMPs learned by the robot from the demonstrations of Figure \ref {fig:realAppli}.\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The prediction of the future trajectory from the learned ProMPs computed from the position information for the 3-targets dataset on the real iCub (Figure \ref  {fig:realDistribution}) after 40\% of observations.\relax }}{39}{figure.caption.15}}
\newlabel{fig:realTrajectoriesPredictions}{{13}{39}{The prediction of the future trajectory from the learned ProMPs computed from the position information for the 3-targets dataset on the real iCub (Figure \ref {fig:realDistribution}) after 40\% of observations.\relax }{figure.caption.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces \leavevmode {\color  {blue}Mean and stdev of the NRMSE of the prediction errors plotted in Figure~\ref  {fig:errBoxWithWithoutForces}, and average time for computing both predictions (time modulation and trajectory via update of the posterior distribution). The computation were performed in Matlab, on a single core (no parallelization).}\relax }}{40}{table.caption.18}}
\newlabel{table:statsError}{{3}{40}{\rev {Mean and stdev of the NRMSE of the prediction errors plotted in Figure~\ref {fig:errBoxWithWithoutForces}, and average time for computing both predictions (time modulation and trajectory via update of the posterior distribution). The computation were performed in Matlab, on a single core (no parallelization).}\relax }{table.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{8.2}}Collaborative object sorting}{40}{subsection.8.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces The prediction of the future trajectory from the learned ProMPs computed from the position and wrench information for the 3-targets dataset on the real iCub (Figure \ref  {fig:realDistribution}) after 40\% of observations.\relax }}{41}{figure.caption.16}}
\newlabel{fig:realTrajectoriesPredictionsWithForces}{{14}{41}{The prediction of the future trajectory from the learned ProMPs computed from the position and wrench information for the 3-targets dataset on the real iCub (Figure \ref {fig:realDistribution}) after 40\% of observations.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Trajectory prediction error (top) and time modulation estimation error (bottom) of the future trajectory with and without wrench information, for the 3-targets dataset on the real iCub (Figure \ref  {fig:realDistribution}) with respect to the number of observed data points.\relax }}{42}{figure.caption.17}}
\newlabel{fig:errBoxWithWithoutForces}{{15}{42}{Trajectory prediction error (top) and time modulation estimation error (bottom) of the future trajectory with and without wrench information, for the 3-targets dataset on the real iCub (Figure \ref {fig:realDistribution}) with respect to the number of observed data points.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Videos}{42}{section.9}}
\newlabel{sec:video}{{9}{42}{Videos}{section.9}{}}
\citation{maeda2016probabilistic}
\citation{ewerton2015learning}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces \leavevmode {\color  {blue}The second experiment with the robot: iCub must sort the objects into two bins, guided by the human. If the object is good, the robot has to put the object in the ``front bin"; if the object is not good, the robot has to put the object in the ``left bin". The gestures to put the objects into the two bins are different. To simplify, the drop locations for the two bins are represented by the targets F and L. After inspecting the object, the human drives the robot towards the front of the left.}\relax }}{43}{figure.caption.19}}
\newlabel{figure:sortingiCub}{{16}{43}{\rev {The second experiment with the robot: iCub must sort the objects into two bins, guided by the human. If the object is good, the robot has to put the object in the ``front bin"; if the object is not good, the robot has to put the object in the ``left bin". The gestures to put the objects into the two bins are different. To simplify, the drop locations for the two bins are represented by the targets F and L. After inspecting the object, the human drives the robot towards the front of the left.}\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10}DISCUSSION}{43}{section.10}}
\newlabel{sec:discussion}{{10}{43}{DISCUSSION}{section.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11}CONCLUSION}{44}{section.11}}
\newlabel{sec:conclusions}{{11}{44}{CONCLUSION}{section.11}{}}
\citation{bishop2006pattern}
\@writefile{toc}{\contentsline {section}{Appendices}{45}{section*.21}}
\@writefile{toc}{\contentsline {chapter}{APPENDICES}{45}{section*.21}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Detail of the inference formula}{45}{Annexe.1.A}}
\newlabel{sec:formulas}{{A}{45}{Detail of the inference formula}{Annexe.1.A}{}}
\newlabel{eq:book1}{{18}{45}{Detail of the inference formula}{equation.1.A.18}{}}
\newlabel{eq:book2}{{19}{45}{Detail of the inference formula}{equation.1.A.19}{}}
\newlabel{eq:book3}{{20}{45}{Detail of the inference formula}{equation.1.A.20}{}}
\newlabel{paramdistrib}{{21}{45}{Detail of the inference formula}{equation.1.A.21}{}}
\newlabel{noteGaussian}{{18}{45}{Detail of the inference formula}{Annexe.1.A}{}}
\bibstyle{plain}
\bibdata{../SOA/SOA}
\global\@namedef{@lastpage@}{46}
\newlabel{eq:marg}{{23}{46}{Detail of the inference formula}{equation.1.A.23}{}}
\newlabel{eq:cond}{{24}{46}{Detail of the inference formula}{equation.1.A.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces \leavevmode {\color  {blue}Predicted trajectories for the second experiment with the robot (Figure \ref  {figure:sortingiCub}). The black circles represent the observations acquired while the human is physically moving the iCub's arm. When the human breaks the contact and releases the arm, the robot predicts the future trajectory and continues the movement. The prior of the recognized ProMP is blue, the posterior ProMP used for prediction is red, the prior ProMP of the other task (i.e., the one that is recognized as not the one currently being executed) is green.\textbf  {Top, F}: the human moves the arm towards the front bin. After few observations ($\sim $ 0.5s) the robot recognizes that the movement corresponds to the ``F'' action. The prior of the F actions is blue, the posterior/prediction is red, the L action is green. \textbf  {Bottom, L}: the human moves the arm towards the left bin. After few observations ($\sim $ 0.25s) the robot has recognized the L action. The prior of the L action is blue, the posterior red, the F action (not recognized) is green.}\relax }}{47}{figure.caption.20}}
\newlabel{figure:sortingiCubTrajectories}{{17}{47}{\rev {Predicted trajectories for the second experiment with the robot (Figure \ref {figure:sortingiCub}). The black circles represent the observations acquired while the human is physically moving the iCub's arm. When the human breaks the contact and releases the arm, the robot predicts the future trajectory and continues the movement. The prior of the recognized ProMP is blue, the posterior ProMP used for prediction is red, the prior ProMP of the other task (i.e., the one that is recognized as not the one currently being executed) is green.\textbf {Top, F}: the human moves the arm towards the front bin. After few observations ($\sim $ 0.5s) the robot recognizes that the movement corresponds to the ``F'' action. The prior of the F actions is blue, the posterior/prediction is red, the L action is green. \textbf {Bottom, L}: the human moves the arm towards the left bin. After few observations ($\sim $ 0.25s) the robot has recognized the L action. The prior of the L action is blue, the posterior red, the F action (not recognized) is green.}\relax }{figure.caption.20}{}}
